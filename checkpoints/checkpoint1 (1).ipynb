{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1: Neural networks and deep learning\n",
    "---\n",
    "*Responsible:* Guillermo Hamity (<ghamity@ed.ac.uk>)\n",
    "\n",
    "In this checkpoint exercise, we will use neural networks to predict the **type** of weather *given* the available ground observations. You will be using observation data from **June 2019** across all UK Met Office weather stations.\n",
    "\n",
    "### Notes on the Dataset\n",
    "* You will be using weather observation data from the UK Met Office Datapoint service\n",
    "* Ground observations are made hourly at weather stations across the length of the UK \n",
    "* The data sample covers data from June 2019\n",
    "* Data collections for each day starts at 6.30pm. All observation data is listed in one day blocks\n",
    "* The time value column refers to the number of minutes after midnight \n",
    "* `Null` values for some features are expected (e.g. Wind Gust)\n",
    "* Data import and preparation is already provided \n",
    "\n",
    "\n",
    "This week, I am not providing example notebooks like `lecture2.ipynb` and `data-science-tools.ipynb` for Unit 2, though these may still be useful to you. Instead, I am **providing the imports for all of the modules and classes that you should need.** Think of these as LEGO blocks; you have the ones you need but may look up how to \"assemble\" them.\n",
    "\n",
    "### Notes on assessment\n",
    "* Try and calculate the answers to the exercises provided. If you are unable to complete the question, describe which approach you _would_ have taken to solve the problem\n",
    "* Code must be understandable and reproducible. Before grading the notebook kernel **may** be restarted and re-run, so make sure that your code can run from start to finish without any (unintentional) errors\n",
    "* If you are unsure on how to proceed please **ask one of the TAs** during the workshop\n",
    "- Notebooks should be submitted by **10am on Friday 9 October 2021** \n",
    "- This CP exercise sheet is divided into **6 sections**, corresponding to parts of the lecture, giving a maximum of **10 marks** in total:\n",
    "\n",
    "| <p align='left'> Title                         | <p align='left'> Exercise nos. | <p align='left'> Number of marks |\n",
    "| ------------------------------------- | ----- | --- |\n",
    "| <p align='left'> 1. Conceptual questions               | <p align='left'>  1–5  | <p align='left'> 3 |\n",
    "| <p align='left'> 2. Data preprocessing and RandomForest                | <p align='left'>  6–9  | <p align='left'> 2. |\n",
    "| <p align='left'> 3. Neural networks in `scikit-learn`  | <p align='left'>  10–11 | <p align='left'> 1.5 | \n",
    "| <p align='left'> 4. Neural networks in `Keras`         | <p align='left'> 12–13 | <p align='left'> 2 |\n",
    "| <p align='left'> 5. Regularisation                     | <p align='left'> 14–15 | <p align='left'> 1.5 |\n",
    "| <p align='left'> **Total** | | <p align='left'> **10** |\n",
    "\n",
    "- The total number of marks allocated for this CP is 10,\n",
    "    - 1 additional mark can be given (maximimally up to 10 marks in total) for \"bonus\" exercise on hyperparameter optimisation. If you are pressed for time, focus on the first five sections; those are the core ones.\n",
    "    - Half marks may be deducted for code legibility (i.e. very difficult to tell what you are doing), or for badly formated plots (i.e. no legends, axis labels etc.). The TAs will use their discression for this so comment code when applicable and keep relevant information in your plots.\n",
    "\n",
    "_Note:_ You can suppress double-printing of plots from the `plot` module by either _(a)_ adding a semicolon after the function call (_i.e._ `plot.<method>(...);`), or _(b)_ by capturing the return `pyplot.Figure` object as a variable (_i.e._ `fig = plot.<method>(...)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard import(s)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Suppress unnecessary ConvergenceWarnings and DeprecationWarnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# Set a random seed variable to make workbook reproducible\n",
    "seed=5\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Switch off multi-threading for TensorFlow\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                                  inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationID</th>\n",
       "      <th>StationName</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gust</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>PressureTrend</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3002</td>\n",
       "      <td>BALTASOUND</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.749</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.1</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>E</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>F</td>\n",
       "      <td>11.6</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>BALTASOUND</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.749</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>E</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>F</td>\n",
       "      <td>11.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002</td>\n",
       "      <td>BALTASOUND</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.749</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>E</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>F</td>\n",
       "      <td>11.6</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3002</td>\n",
       "      <td>BALTASOUND</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.749</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>R</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3002</td>\n",
       "      <td>BALTASOUND</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.749</td>\n",
       "      <td>-0.854</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>1260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>R</td>\n",
       "      <td>10.9</td>\n",
       "      <td>92.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StationID StationName  Elevation  Latitude  Longitude        Date  Time  \\\n",
       "0       3002  BALTASOUND       15.0    60.749     -0.854  2018-05-31  1020   \n",
       "1       3002  BALTASOUND       15.0    60.749     -0.854  2018-05-31  1080   \n",
       "2       3002  BALTASOUND       15.0    60.749     -0.854  2018-05-31  1140   \n",
       "3       3002  BALTASOUND       15.0    60.749     -0.854  2018-05-31  1200   \n",
       "4       3002  BALTASOUND       15.0    60.749     -0.854  2018-05-31  1260   \n",
       "\n",
       "   Gust  Temperature  Visibility WindDirection  WindSpeed  Pressure  \\\n",
       "0   NaN         16.1     30000.0             E        8.0    1019.0   \n",
       "1   NaN         14.9     22000.0             E        8.0    1019.0   \n",
       "2   NaN         14.0     14000.0             E        6.0    1018.0   \n",
       "3   NaN         12.9     12000.0           ENE        2.0    1019.0   \n",
       "4   NaN         12.0      9000.0             E        2.0    1019.0   \n",
       "\n",
       "  PressureTrend  DewPoint  Humidity  Type  \n",
       "0             F      11.6      74.5     0  \n",
       "1             F      11.8      81.5     0  \n",
       "2             F      11.6      85.4     0  \n",
       "3             R      11.0      88.1     0  \n",
       "4             R      10.9      92.9     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the prepared weather data\n",
    "obs = pd.read_csv('weather.csv')\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106553, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Time</th>\n",
       "      <th>Gust</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106553.000000</td>\n",
       "      <td>106553.000000</td>\n",
       "      <td>106553.000000</td>\n",
       "      <td>106553.000000</td>\n",
       "      <td>106553.000000</td>\n",
       "      <td>7703.000000</td>\n",
       "      <td>106442.000000</td>\n",
       "      <td>92662.000000</td>\n",
       "      <td>102060.000000</td>\n",
       "      <td>99530.000000</td>\n",
       "      <td>106402.000000</td>\n",
       "      <td>106397.000000</td>\n",
       "      <td>106553.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6147.845636</td>\n",
       "      <td>114.466594</td>\n",
       "      <td>53.673022</td>\n",
       "      <td>-2.829034</td>\n",
       "      <td>702.914418</td>\n",
       "      <td>33.043749</td>\n",
       "      <td>14.958912</td>\n",
       "      <td>25698.164404</td>\n",
       "      <td>8.999510</td>\n",
       "      <td>1018.748337</td>\n",
       "      <td>10.348008</td>\n",
       "      <td>76.185240</td>\n",
       "      <td>0.99603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15821.503845</td>\n",
       "      <td>171.669120</td>\n",
       "      <td>2.466079</td>\n",
       "      <td>2.269594</td>\n",
       "      <td>412.057262</td>\n",
       "      <td>13.424855</td>\n",
       "      <td>4.294516</td>\n",
       "      <td>14263.873943</td>\n",
       "      <td>6.087882</td>\n",
       "      <td>6.327468</td>\n",
       "      <td>3.120565</td>\n",
       "      <td>17.208653</td>\n",
       "      <td>0.92971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3002.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>49.207900</td>\n",
       "      <td>-10.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>976.000000</td>\n",
       "      <td>-28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3204.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>51.565000</td>\n",
       "      <td>-4.149000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>65.300000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3414.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>53.175000</td>\n",
       "      <td>-2.663000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3769.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>55.285000</td>\n",
       "      <td>-1.097000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99142.000000</td>\n",
       "      <td>1245.000000</td>\n",
       "      <td>60.749000</td>\n",
       "      <td>1.348000</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1036.000000</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           StationID      Elevation       Latitude      Longitude  \\\n",
       "count  106553.000000  106553.000000  106553.000000  106553.000000   \n",
       "mean     6147.845636     114.466594      53.673022      -2.829034   \n",
       "std     15821.503845     171.669120       2.466079       2.269594   \n",
       "min      3002.000000       2.000000      49.207900     -10.250000   \n",
       "25%      3204.000000      20.000000      51.565000      -4.149000   \n",
       "50%      3414.000000      65.000000      53.175000      -2.663000   \n",
       "75%      3769.000000     132.000000      55.285000      -1.097000   \n",
       "max     99142.000000    1245.000000      60.749000       1.348000   \n",
       "\n",
       "                Time         Gust    Temperature    Visibility      WindSpeed  \\\n",
       "count  106553.000000  7703.000000  106442.000000  92662.000000  102060.000000   \n",
       "mean      702.914418    33.043749      14.958912  25698.164404       8.999510   \n",
       "std       412.057262    13.424855       4.294516  14263.873943       6.087882   \n",
       "min         0.000000     0.000000      -1.200000     20.000000       0.000000   \n",
       "25%       360.000000    29.000000      12.000000  14000.000000       5.000000   \n",
       "50%       720.000000    32.000000      14.500000  25000.000000       8.000000   \n",
       "75%      1020.000000    39.000000      17.500000  35000.000000      11.000000   \n",
       "max      1380.000000   105.000000      31.600000  75000.000000      81.000000   \n",
       "\n",
       "           Pressure       DewPoint       Humidity          Type  \n",
       "count  99530.000000  106402.000000  106397.000000  106553.00000  \n",
       "mean    1018.748337      10.348008      76.185240       0.99603  \n",
       "std        6.327468       3.120565      17.208653       0.92971  \n",
       "min      976.000000     -28.200000       0.800000       0.00000  \n",
       "25%     1015.000000       8.400000      65.300000       0.00000  \n",
       "50%     1018.000000      10.500000      79.200000       1.00000  \n",
       "75%     1024.000000      12.500000      90.000000       1.00000  \n",
       "max     1036.000000      22.700000     100.000000       3.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will use **8** input features (provided) and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8 input feature variables, 1 target variable data, and names of the 3 weather types\n",
    "features = ['Latitude', 'Elevation', 'Temperature', 'Visibility', 'WindSpeed', 'Pressure', 'Humidity', 'WindDirection']\n",
    "output   = ['Type']\n",
    "wtype    = ['Clear', 'Cloudy', 'Precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define derived dataset containing only the relevant columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86313, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce to feature and type columns\n",
    "dataset = obs[features + output]\n",
    "\n",
    "# Drop duplicates and null values \n",
    "dataset = dataset.drop_duplicates().dropna()\n",
    "\n",
    "# Drop unrecorded weather type\n",
    "dataset = dataset[dataset.Type != 3]\n",
    "\n",
    "# Check shape \n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conceptual questions (3 Marks)\n",
    "---\n",
    "This section covers **5** exercises on conceptual understanding of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Which are the most used activation functions and why do we (typically) need non-linear activation functions in neural networks? (0.5 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid activation, RelU, Softmax and tanh\n",
    "#We need non-linear functions so that the neural network can do more complex tasks. In order to perform backpropogation, we \n",
    "#need to differentiate a non-linear function otherwise the derivative is constant and thus independent of the input.\n",
    "#Linear functions are composed of linear parts so Hidden layers would be useless without non-linear activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Why do we need deep neural networks and which are the main differences between deep and shallow learning? (0.5 Mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The performance of Deep learning algorithms scales much better with the amount of data than other learning algorithms \n",
    "#making it more accurate and high performance on when given complex tasks.\n",
    "#Deep neural networks are able to get the relevant features whereas for shallow neural networks we must provide them.\n",
    "#Deep neural networks have two or more hidden layers\n",
    "#Deep neural networks can make use of high dimensional data whereas shallow neural networks cannot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Discuss the Bias-variance trade-off and its relation to underfitting and overfitting of a model. Which are the caractheristics of an ideal model?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you increase the bias of an algorithm  then you decrease the variance and vice versa. This is the Biad-variance trade-off.\n",
    "#An algorithm with low bias and high variance has been overfit (High loss on trsting data)\n",
    "#An algorithm with high bias and low variance has been underfit (poor performance on training data)\n",
    "#Ideal models have a low bias and a low variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Given a neural network with 4 input nodes, 2 layers with 5 nodes each, and 1 output node, what is the total number of free (trainable) parameters in the network? Does it matter which activation function(s) are used?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free parameters from bias = 5 x 2 + 1 = 11\n",
    "#free parameters from connections between layers = (4x5)+(5x5) + (5x1) = 20+25+5 = 50\n",
    "\n",
    "#free paramaters = 61\n",
    "#this is independent of the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. What are appropriate choice for _(a)_ the number of output nodes and _(b)_ output activation function(s) for each of the following tasks, and why? (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regression of the $x$, $y$, and $z$ coordinates of a single particle in an arbitrary coordinate system\n",
    "2. Regression of particle energy of a single particle\n",
    "3. Classification of two processes (signal vs. background)\n",
    "4. Classification among *N* classes (dog vs. cat vs. fish vs. ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.a) 3 output nodes ,b) RelU, because it is fast to converge and avoids vanishing gradients\n",
    "#2.a) 1 output node  ,b) RelU, because it is fast to converge and avoids vanishing gradients\n",
    "#3.a) 2 output nodes ,b) sigmoid function because it only exists between 0 and 1 which is useful since we want probability outputs.\n",
    "#4.a) N output nodes ,b) softmax activation function, because it assigns 0 to 1 that must sum to 1 between all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6. Given some data points and regression/classification problem, write the appropite cost function and compare your solution to that from sklearn (0.5 marks)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression** \n",
    "\n",
    "A good **loss function** for regression is the **Mean Squared Error**. \n",
    "\n",
    "For $N$ samples with targets $Y$, our prediction $\\bar{Y}$ has an MSE of:\n",
    "\n",
    "\n",
    "$\\mathrm{MSE} = \\frac{\\sum[(\\bar{Y}-Y)^2]}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Problem\n",
    "\n",
    "# 3 Targets for regression \n",
    "Y = np.array([0.,1.,0.5])\n",
    "# 3 Predicted values (at random)\n",
    "YPred = np.random.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function (Mean Square Error):\n",
    "def mse(YPred,Y):\n",
    "    error = np.sum((YPred-Y)**2)/len(Y) #equation for mean squared error target Y\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My MSE function is Correct\n"
     ]
    }
   ],
   "source": [
    "# Comparing our function to the sklearn MSE\n",
    "prediction = np.random.rand(Y.shape[0])\n",
    "print (\"My MSE function is {}\".format(\"Correct\" if mse(prediction,Y) == metrics.mean_squared_error(prediction,Y) else \"Wrong\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**\n",
    "\n",
    "Log Loss from the lecture notes is appropiate for binary classification, where our prediction is a probaility of `label = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Random class labels (0 or 1)\n",
    "Y = np.random.randint(0,2,10)\n",
    "# 10 Random Probabilities\n",
    "YPred = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(YPred,Y):\n",
    "    logerror = (-1/len(Y))*np.sum((Y*np.log(YPred))+(1-Y)*np.log(1-YPred)) #equation for logloss with target Y\n",
    "    return logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it matches the sklearn log_loss\n",
    "logloss(YPred,Y) == metrics.log_loss(Y.astype(int),YPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing and RTs (2 mark)\n",
    "---\n",
    "This section covers **4** exercises on data preparation, feature standardisation, and dataset splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import preprocessing # Import preprocessing for String-Int conversion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**_Comment on target format and one-hot encoding:_** By default, the target column (`Type`) contains one integer (0, 1, or 2) for each example, the integer specifying one of three possible types of weather. However, for doing multi-class classification (which this is), we want our neural network to have one output node per class (_i.e._ 3 output nodes in this case), such that the activation of each output node is interpreted as the likelihood for a given sample being of the type in question. Therefore, the target should also be a 3-element vector for each sample; this vector should be all zeros, except for a $1$ at the index corresponding to the type in question. This is called **one-hot encoding**, and a few examples are shown below:\n",
    "\n",
    "- type = 0 $\\to$ one-hot = $[1, 0, 0]$ for 3 classes\n",
    "- type = 1 $\\to$ one-hot = $[0, 1, 0]$ for 3 classes\n",
    "- type = 2 $\\to$ one-hot = $[0, 0, 1]$ for 3 classes\n",
    "\n",
    "This is the target towards which a neural network classifier is trained: That is, ideally, for an example of type 0, the network will output a large activation ($\\approx 1$) on the first output node (interpreted as a large likelihood for the first weather type), and very small activations ($\\ll 1$) on the two other output nodes (intepreted as small likelihoods for the two other weather types); and so on.\n",
    "\n",
    "The same type of one-hot encoding can be performed for any number of target classes $N_{c}$, which just results in $N_{c}$-element target vectors with a single non-zero entry each.\n",
    "\n",
    "To be user friendly, however, `scikit-learn` allows us to use integer targets for multi-class classification — it does the one-hot encoding for us \"under the hood.\" Similarly, `keras`, _can_ also allow us to use integer targets for multi-class classification, provided we use the appropropriate loss (`sparse_categorical_crossentropy`). Otherwise (if we use `categorical_crossentropy` loss), it expects one-hot encoded targets. Which approach you choose is up to you — but now you know what goes on.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Prepare the feature and target arrays (0.5 mark)\n",
    "- Randomly sample **3,500** observations per weather type (**10,500** observations in total) from `dataset` into a new `pandas.DataFrame`; call it `sample`.\n",
    "- One-hot encode the **wind direction** variable (_i.e._ $N$ to $[1, 0, \\ldots, 0]$, $NNE$ to $[0, 1, \\ldots, 0]$, _etc._ ), to allow us to input it to the neural network. There are 16 unique directions so we need to transform 1 feature into 16 features.\n",
    "The exact order of the encoding (_i.e._ which direction corresponds to which index) doesn't matter. *Hint:*\n",
    "  - *Either:* Use the scikit-learn `ColumnTransformer` with the `OneHotEncoder` applied to the `WindDirection` column, and let the remainder of the features pass through un-transformed.\n",
    "  - *Or:* Use the `OneHotEncoder` class directly on the `WindDirection` column (use `sparse=False` in the `OneHotEncoder` constructor), and then concatenate with a `numpy.array` containing the remaining features.\n",
    "- Define `numpy.arrays` named `X` and `y` containing the training features (the 7 unmodified ones plus the one-hot encoded wind directions) and target, respectively.\n",
    "- Argue whether the shapes of `X` and `y` are as expected/as they should be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 'Latitude', 'Elevation', 'Temperature', 'Visibility', 'WindSpeed', 'Pressure', 'Humidity']\n"
     ]
    }
   ],
   "source": [
    "#For convenience concatenate the wind direction and other features \n",
    "# in the order that you can use this feature name variable\n",
    "feature_names = list(range(16))+features[:-1]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle dataset\n",
    "\n",
    "\n",
    "dataset = dataset.sample(frac = 1).reset_index(drop=True)  \n",
    "#put 3500 observations for each weather type into a list of 3\n",
    "frames =[dataset[dataset.Type == 0].head(3500),dataset[dataset.Type == 1].head(3500),dataset[dataset.Type == 2].head(3500)] \n",
    "#concatenate list to create 10500x9 dataframe\n",
    "sample = pd.concat(frames)\n",
    "\n",
    "#One-hot encode WindDirection ie split feature (index 7) into 16 features \n",
    "transformer = ColumnTransformer(transformers = [('',OneHotEncoder(),[7])],remainder = 'passthrough')\n",
    "\n",
    "transformed = transformer.fit_transform(sample)\n",
    "transformed_sample = pd.DataFrame(transformed,columns = transformer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 23)\n",
      "(10500,)\n"
     ]
    }
   ],
   "source": [
    "#Separate features and target into X and y arrays respectively\n",
    "X = transformed_sample[transformed_sample.columns[0:23]].values\n",
    "\n",
    "#flatten y array to 1D\n",
    "y = sample['Type'].values.flatten()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "#X is (10500,23) which means it includes all 10500 data points,7 of the original features, and 16 wind direction colums \n",
    "#y is (10500,) since it is one row containing the target values for all datapoints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Train a Random Forest, evaluate performance, explore features (1.5 mark)\n",
    "\n",
    "Decision trees work well with a mixture of features (of different scales, and both binary and continuous data), so we will train a random forest to do the job of categorisation.\n",
    "\n",
    "You are given the train test split (70% training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7350, 23) (3150, 23) (7350,)\n"
     ]
    }
   ],
   "source": [
    "#Import random fosets and confusion matrix metric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "print(x_train.shape,x_test.shape,y_train.ravel().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a `RandomForestClassifier` with a `GridSearchCV` over the following input parameters to the mode'. Split the dataset into only 3 cross validation folds to make it a little faster (Hint: see `GreidSearchCV` function documentation)\n",
    "2. Check the overal accuaracy on the testing set\n",
    "3. What is the best set of hyperparametrs the scan has found? \n",
    "\n",
    "*Hint:* the final random forest that is chosen can be returned with th the `best_estimator_` member of the `GridSearchCV` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scan a broad range of parameters to use for the RandomForest\n",
    "rf_dic={\n",
    "    \"n_estimators\":[10,50,200,500],\n",
    "    \"max_features\": [\"sqrt\",\"log2\"],\n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"max_depth\": [4,8,30]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Perform a random forest with gridsearch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(rfc,rf_dic,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\daml\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#define random forest classifier\n",
    "rfc=RandomForestClassifier(n_estimators=100, criterion = 'gini',max_features=5, max_depth=4,random_state=1)\n",
    "#Perform a random forest with gridsearch\n",
    "grid_search = GridSearchCV(rfc,rf_dic,n_jobs=7, cv = 3)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the estimator with the highest score in the grid search\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best set of hyperparams\n",
    "grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print accuracy of model\n",
    "y_pred = grid_search.predict(x_train)\n",
    "print(\"Accuracy Training:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Accuracy Testing:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Classification Accuracy**\n",
    "\n",
    "4. Use the `confusion_matrix` method on the **test data** to return the confusion matrix normalised over the true lables, i.e. sum over rows should sum to 100%. Use the given colormap to plot the confusion matrix in a heatmap.\n",
    "    - Define the axis tick names to represent Clear, Cloudy or Precip\n",
    "    - Use suitable x and y axis labels\n",
    "    \n",
    "5. What are the true positive rates for clear, cloudy and perp? \n",
    "6. What is the probability that rain is forcast on a sunny day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "matrix = ConfusionMatrixDisplay.from_estimator(\n",
    "    grid_search,x_test,y_test,cmap=plt.cm.Blues,normalize='true',\n",
    "    display_labels=(('clear'),('cloudy'),('precip')))\n",
    "plt.xlabel('Predicted weather')\n",
    "plt.ylabel('Actual Weather')\n",
    "\n",
    "#5.True positives clear = 0.73, cloudy 0.61, rain = 0.84\n",
    "#6. 0.021 chance of rain being forecast on sunny day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Understanding Feature Importance**\n",
    "\n",
    "There are several ways to understand which **features are important** to the \n",
    "decision tree. The most common is to look at `feature_importances_` list which is calculated at training time. This quantifies by how much each feature splits the dataset, the higher the number, the more imporant the feature. In random forests were we have 100s of trees, the importance is an gregate.\n",
    "\n",
    "\n",
    "*Note:* below the code assumes the random forest CV search is still `grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given plotting example for feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(range(23), grid_search.best_estimator_.feature_importances_)\n",
    "ax.set_yticks(range(23),feature_names)\n",
    "ax.set_title(\"Training Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. In the RF I trained, wind direction has little impact on the performance, while Pressure, Visibility and Humidity seem like natural important features.\n",
    "\n",
    "The problem with `feature_importances_` is that they are **calulated and biased towards the training dataset**, so may not represent the most relevant features for classifying on the **testing dataset**.\n",
    "\n",
    "\n",
    "We can use `permutation_importance` to get a more accurate representation on the feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will randomly permute (shuffle) one feature at a time, and look at how much the accuracy changes. We can perform this permutation several times (`n_repeats`) and get an average impact on the accuracy, and a std deviation.\n",
    "\n",
    "7. Complete the permutation importance function below\n",
    "    - Use the test dataset\n",
    "    - Permute each feature 20 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(grid_search, x_test, y_test,n_repeats = 20,\n",
    "                                random_state=42, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Make the feature importance plot as above using \n",
    "    - `result.importances_mean` as the feature importances\n",
    "    - `result.importances_std` for the `barh` parameter `xerr=`\n",
    "    - Comment on how the imporatnces change on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(range(23), result.importances_mean,xerr=(result.importances_std))\n",
    "ax.set_yticks(range(23),feature_names)\n",
    "ax.set_title(\"Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "#Overall the feature importances have decreased\n",
    "#Temperature is relatively less important. Elevation is significantly less important than windspeed,\n",
    "#and both are significantly less important than the other features.\n",
    "#Humidity becomes less important than visibility on the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Finally we can look at the impact of individual features on the probablity of a **particular class**.\n",
    "\n",
    "Using `PartialDependenceDisplay` we choose a set of features that we allow to vary within a range, while other features remain fixed. We can look at how the probability estimate changes on average for any one of our targets. \n",
    "\n",
    "9. Complete the `PartialDependenceDisplay.from_estimator` function by:\n",
    "    - adding your random forest estimator\n",
    "    - using the first 100 data points of the test dataset as input\n",
    "    - Use the `Humidity`, `Pressure` and `Visibility` features. These feature values are scanned while the others remain fixed (*Hint:* `features` parameter)\n",
    "    - Look at the impact on the `Precipitaion` class probability (*Hint:* `target` parameter)\n",
    "10. Comment on the trends shown over the 3 features on the probability it will rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(feature_names)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Decision Tree\")\n",
    "\n",
    "tree_disp = PartialDependenceDisplay.from_estimator(\n",
    "    grid_search,x_test[:100],features =[22,21,19],\n",
    "    target = [2],\n",
    "    ax=ax)\n",
    "\n",
    "tree_disp.axes_[0][0].set_xlabel(\"Humidity\")\n",
    "tree_disp.axes_[0][1].set_xlabel(\"Pressure\")\n",
    "tree_disp.axes_[0][2].set_xlabel(\"Visibility\")\n",
    "\n",
    "#Rain increase with humidity as expected.\n",
    "#After a certain pressure point, rain decreases with pressure\n",
    "#Rain decreases with visibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural networks in `scikit-learn` (1.5 mark)\n",
    "---\n",
    "This section covers exercises on constructing and training neural networks using the `scikit-learn` library, as well as evaluating neural network performance. `scikit-learn` provide many, very easy to use ML algorithms, including neural networks. These are called `MLPClassifier` (MLP = multi-layer perceptron; a historic name for densely connected, feed-forward neural networks) when used for classification, and `MLPRegressor` when used for regression. We will focus on the former for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Standardise the relevant features  and split data (0.5 mark)\n",
    "We need some additional processing of the input features to make them appropiate for the neural network. \n",
    "\n",
    "- Use our feature array `X`, and standardize the features.\n",
    "\n",
    "    _Note:_ You shouldn't standardise the one-hot encoded wind directions; they already have the desired format. Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "    - Hint:\n",
    "\n",
    "        - Use the scikit-learn `StandardScaler`\n",
    "        - Or use the scikit-learn `MinMaxScaler`\n",
    "\n",
    "- Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "    - The number of columns should match, and depending on the choice of standardisation, the last 7 columns should either have:\n",
    "      - (Using `StandardScaler`) means = 0 and standard deviations = 1; or\n",
    "      - (Using `MinMaxScaler`) min = 0, max = 1\n",
    "      \n",
    "- Reserve **30%** of data for testing. Check whether the resulting arrays have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 23)\n",
      "8.61204864035937e-14\n",
      "0.9999999999999981\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "scaler =StandardScaler()\n",
    "X[:,16:] = scaler.fit_transform(X[:,16:])\n",
    "\n",
    "#X = np.concatenate((X[:,:16],scaled),axis = 1)\n",
    "\n",
    "print(np.mean(X[:,16]))\n",
    "print(np.std(X[:,16]))\n",
    "\n",
    "#Separate 30% out to X_test and 70% to X_train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Construct, train, and evaluate a neural network  (1 mark)\n",
    "\n",
    "- Create an `MLPClassifier` which\n",
    "    - has **1 hidden layer of 50 neurons** \n",
    "    - has **no regularization term**\n",
    "    - trains for a maximum of **100 epochs** \n",
    "    - uses a batch size of **32**\n",
    "- Fit the classifier using the standard `.fit()` member method.\n",
    "- Plot the loss function value as a function of number of epochs (0.5 of mark).\n",
    "  You can access the loss history through the `.loss_curve_` attribute of the `MLPClassifier` instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\envs\\daml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss values')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_iter = 100\n",
    "clf = MLPClassifier(max_iter = max_iter,alpha = 0,hidden_layer_sizes = (50,),\n",
    "                   batch_size = 32)\n",
    "clf.fit(X_train,y_train)\n",
    "loss_values =clf.loss_curve_\n",
    "#print(loss_values)\n",
    "#print(len(loss_values))\n",
    "\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Using the testing dataset: \n",
    "    - Compute the overall accuracy for the classifier using the `MLPClassifier`'s `.score()` member method for both testing and training datasets.\n",
    "    - Compute the confusion matrix (normalised in true labels), and plot it \n",
    "- Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Training:\",clf.score(X_train,y_train))\n",
    "print(\"Accuracy Testing:\",clf.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "matrix = ConfusionMatrixDisplay.from_estimator(\n",
    "    clf,X_test,y_test,cmap=plt.cm.Blues,normalize='true',\n",
    "    display_labels=(('clear'),('cloudy'),('precip')))\n",
    "plt.xlabel('Predicted weather')\n",
    "plt.ylabel('Actual Weather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural networks in `Keras` (2 marks)\n",
    "---\n",
    "This section covers exercises on constructing and training neural networks using the `Keras` library. `scikit-learn` is very easy to use, but libraries like `Keras` provide a lot more flexibility, which is why we will be using these extensively in the last two units of the _'Data science tools and machine learning'_ track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Construct a neural network in `Keras` (1 mark)\n",
    "\n",
    "- Create a `keras.Model` using the **Keras functional API**. The network should have:\n",
    "    - An input layer with the same number of nodes as the number of features in `X`.\n",
    "    - A single, densely connected hidden layer with **50 nodes** equipped with **ReLU activation**.\n",
    "    - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "- Compile the model the using the **Adam optimiser**, add `'accuracy'` as metric, and use either:\n",
    "    - `categorical_crossentropy` loss, if you have one-hot encoded the targets `y`, or\n",
    "    - `sparse_categorical_crossentropy` loss if you hare using integer-valued targets.\n",
    "- Use the `.summary()` member method to print an overview of the model you have created, explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7350, 23)\n",
      "(3150, 23)\n",
      "(7350,)\n",
      "(3150,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 23)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,353\n",
      "Trainable params: 1,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(23,))\n",
    "hidden_layer = Dense(50, activation=tf.nn.relu)(inputs)\n",
    "outputs = Dense(3, activation=tf.nn.softmax)(hidden_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "#This sumamry shows input layer with 23 nodes in a column with 0 parameters\n",
    "#a hidden layer with 50 nodes (shape None,50) with 1200 parameters\n",
    "#and the output layer with 3 nodes(shape None,3) with 153 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Train a `Keras` neural network (1 mark)\n",
    "\n",
    "- Use the `.fit()` member method to train the network on the **training dataset** for **100 epochs** with a **batch size of 32**. Use **20% of the data for validation** and make sure to have `Keras` **shuffle** the training data between epochs. Save the fit history by doing `history_mld = .....`\n",
    "- Print the classification accuracy using the `.evaluate()` member method, for both the training and testing dataset. Comment on the results.\n",
    "- Plot val_loss and loss functions from the fit history. On the same plot, plot the sklearn curve from the excercise above. Note the sklearn NN does not provide a complementary validation loss history, so only plot the training loss.\n",
    "- Comment on the results of the overall accuracy compared to the scikit-learn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7350,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history= model.fit(X_train,y_train,batch_size = 32,epochs = 100,shuffle = True,validation_split = 0.2)\n",
    "val_loss, val_accuracy =model.evaluate(X_train,y_train)\n",
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "\n",
    "\n",
    "print(\"Training loss, training accuracy:\",val_loss, val_accuracy )\n",
    "print(\"Test loss, test accuracy:\",loss, accuracy)\n",
    "\n",
    "#The training set accuracy is and test set accuracy are quite similar but the training set accuracy\n",
    "#is higher as expect.\n",
    "#The training data loss is significantly lower than the test data loss which suggests that the model\n",
    "#has not been underfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Similar results to sk-learn model above\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "#Similar results to sk-learn model above\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "#plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(loss_values)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'val loss',\"skilearn loss\"], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "#Loss on the training set for keras is very similar to the loss in the skilearn method\n",
    "#As expected the validation loss is higher than the training loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regularisation (1.5 marks)\n",
    "---\n",
    "This section covers **2** exercises on the impact of weight regularisaton. Note that $L_{1}$- and $L_{2}$-regularisation may also be applied to the activation of intermediate layers. Also, a similar regularising effect could be achieved using **dropout** regularisation, which you are encouraged to try out, but which we won't study in this CP exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Define `Keras` model factory method (0.5 mark)\n",
    "\n",
    "- Define a python function called `big_model_fn` which takes the followng three arguments:\n",
    "    - `l1`: A float specifying the $L_{1}$ regularisation factor (default value: 0)\n",
    "    - `l2`: A float specifying the $L_{2}$ regularisation factor (default value: 0)\n",
    "    - `name`: A string, specifying the name of the model (default value: None)\n",
    "- Indside the function, you should:\n",
    "    - Construct a `Keras` model using the functional API, which has:\n",
    "        - An input layer with the same number of nodes as the number of features in `X`.\n",
    "        - **Two** densely connected hidden layer with **100 nodes** each, both equipped with **ReLU activation**.\n",
    "        - Both hidden layers should be subject to kernel regularisation (_i.e._ weight regularisation) with the regularisation factors specified as an input.\n",
    "        - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "        - A name given by the corresponding argument.\n",
    "    - Compile the model in the same way as in **Exercise 14.**\n",
    "- The function should return the compiled `Keras` model. \n",
    "\n",
    "The method will provide a convenient way of constructing and compiling a number of \"big\"/deep `Keras` models which differ only by their regularisation and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_model_fn(l1=0,l2=0,name=None):\n",
    "    inputs = Input(shape=(23,))\n",
    "    hidden_layer1 = Dense(100, activation=tf.nn.relu, kernel_regularizer = l1_l2(l1=l1, l2=l2))(inputs)\n",
    "    hidden_layer2 = Dense(100, activation=tf.nn.relu, kernel_regularizer = l1_l2(l1=l1 , l2=l2))(hidden_layer1)\n",
    "    outputs = Dense(3, activation=tf.nn.softmax)(hidden_layer2)\n",
    "\n",
    "    model = Model(name = name, inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics =['accuracy'])\n",
    "\n",
    "    return model.fit(X_train,y_train,batch_size = 32,epochs = 100,shuffle = True,validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Train \"big\" models with and without regularisation (1 mark)\n",
    "\n",
    "- Construct three \"big\" model using the factory method:\n",
    "     - One with default parameters\n",
    "     - One with `l1=0.003` and  `name='model_L1'`\n",
    "     - One with `l2=0.03`  and `name='model_L2'`\n",
    "- Train each one as in **Exercise 15.**\n",
    "- Compare first the loss history of the un-regularised \"big\" model to that of the small model from **Exercise 15** using the `plot.loss()` method.\n",
    "- Then, compare the loss histories of all three \"big\" models with that of the small model.\n",
    "- Plot the loss and val loss of all 4 models. Target these points:\n",
    "    - Compare the performance of deep vs shallow models on the testing sets\n",
    "    - Compare the level of ovetraining (training vs testing loss)\n",
    "    - Note: Don't be alarmed if the shallow network performs slightly better that the deeper ones, this is dataset dependant.\n",
    "- Copy the same plotting code, but this time plot the training and validation accuracy\n",
    "- Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = big_model_fn(0,0,None)\n",
    "history2 = big_model_fn(0.003,0,'model_L1')\n",
    "history3 = big_model_fn(0.03,0,'model_L2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history1.history['loss'])\n",
    "ax.plot(history2.history['loss'])\n",
    "ax.plot(history3.history['loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history1.history['val_loss'])\n",
    "ax.plot(history2.history['val_loss'])\n",
    "ax.plot(history3.history['val_loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_ylim(0.2,2)\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('model loss')\n",
    "ax.legend(['unregularised loss', 'regularisation = 0.003 loss','regularisation =0.03 loss','shallow loss',\n",
    "              'unregularised val_loss','regularisation = 0.003 val_loss','regularisation = 0.03 val_loss','shallow val_loss' ], loc='upper right')\n",
    "\n",
    "#See below for zoomed in plot\n",
    "#The shallow NN performs best overall with low loss on the training set and the low \n",
    "#loss on the testing set.\n",
    "#The regularised deep NNs are underfit. The models have a similar loss on the training and validation sets.\n",
    "#The unregularised deep NN is overfit. There is very low loss on the training set, but high loss\n",
    "#on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history1.history['loss'])\n",
    "ax.plot(history2.history['loss'])\n",
    "ax.plot(history3.history['loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history1.history['val_loss'])\n",
    "ax.plot(history2.history['val_loss'])\n",
    "ax.plot(history3.history['val_loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_ylim(0.2,0.9)\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('zoomed in model loss')\n",
    "ax.legend(['unregularised loss', 'regularisation = 0.003 loss','regularisation =0.03 loss','shallow loss',\n",
    "              'unregularised val_loss','regularisation = 0.003 val_loss','regularisation = 0.03 val_loss','shallow val_loss' ], loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "ax.set_ylim(0.55)\n",
    "plt.xlabel('epoch')\n",
    "plt.title('model accuracy')\n",
    "plt.legend(['unregularised', 'regularisation = 0.003','regularisation =0.03','shallow',\n",
    "            'unregularised val_accuracy','regularisation = 0.003 val_accuracy','regularisation = 0.03 val_accuracy' ], loc='lower right')\n",
    "#As expected overfit unregularised deep NN has the highest accuracy, but low validation accuracy\n",
    "#we see the shallow NN with a high accuracy.\n",
    "#Following this is both the regularised validation  sets.\n",
    "#We confirm that the regularised deep NNs are underfit since they are as/more accurate on validation sets as they \n",
    "#are on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
